{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595994036745",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(Y,beta,X,lamd,p,K):\n",
    "    sum=0\n",
    "    \n",
    "    for k in range(K):\n",
    "        sum_betaX=0\n",
    "\n",
    "        for j in range(p):\n",
    "            sum_betaX=sum_betaX+beta[j,k]*X[j,k,:]\n",
    "\n",
    "        sum=sum+0.5*torch.norm(Y[k,:].flatten()-sum_betaX.flatten())**2\n",
    "    \n",
    "    norm_infinite,indice=torch.max(torch.abs(beta),1)\n",
    "    sum=sum+lamd*torch.sum(norm_infinite)\n",
    "\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initialize settings\n",
    "p=10\n",
    "K=5\n",
    "n_k=60\n",
    "lamd=0\n",
    "\n",
    "X=torch.randn(p,K,n_k)\n",
    "for j in range(p):\n",
    "    for k in range(K):\n",
    "        X[j,k,:]=X[j,k,:]/torch.norm(X[j,k,:])\n",
    "\n",
    "beta_true=torch.randint(low=-5,high=5,size=[p,K])\n",
    "# print(beta_true)\n",
    "Y=torch.zeros(K,n_k)\n",
    "\n",
    "for k in range(K):\n",
    "    sum=0\n",
    "    for j in range(p):\n",
    "        sum=sum+beta_true[j,k]*X[j,k,:]\n",
    "    Y[k,:]=sum+torch.tensor(np.random.normal(loc=0,scale=0,size=X[j,k,:].size())).float()\n",
    "\n",
    "# print(Y.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C_ij\n",
    "C=torch.zeros(p,K)\n",
    "for j in range(p):\n",
    "    for k in range(K):\n",
    "        C[j,k]=torch.matmul(X[j,k,:].flatten(),Y[k,:].flatten())\n",
    "        # print(C[j,k])\n",
    "#D_ij^k\n",
    "D=torch.zeros(p,p,K)\n",
    "for k in range(K):\n",
    "    for i in range(p):\n",
    "        for j in range(p):\n",
    "            D[i,j,k]=torch.matmul(X[i,k,:].flatten(),X[j,k,:].flatten())\n",
    "\n",
    "\n",
    "# beta=torch.zeros(size=beta_true.size())\n",
    "# print(C.size())\n",
    "# print(D.size())\n",
    "\n",
    "# print(D[:,:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(18844.9473)\n"
    }
   ],
   "source": [
    "# beta=beta_true+torch.tensor(np.random.normal(loc=0,scale=9,size=beta_true.size())).float()\n",
    "beta=torch.tensor(np.random.normal(loc=0,scale=25,size=beta_true.size())).float()\n",
    "loss=Loss(Y,beta,X,lamd,p,K)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_blcok(beta,p,K,lamd,X,Y,C,D,j_round):\n",
    "    \n",
    "    alpha=beta\n",
    "    for k in range(K):\n",
    "        beta[j_round,k]=C[j_round,k]-torch.matmul(beta[:,k].flatten().float(),D[:,j_round,k].flatten().float())+beta[j_round,k]*D[j_round,j_round,k]\n",
    "\n",
    "    if (lamd!=0):\n",
    "        if (torch.sum(torch.abs(alpha[j_round,:]))<=lamd):\n",
    "            beta[j_round,:]=0\n",
    "    \n",
    "        alpha_j=alpha[j_round,:]\n",
    "        alpha_j_abs=torch.abs(alpha_j)\n",
    "        alpha_sorted,index1=torch.sort(alpha_j_abs,descending=True)\n",
    "        alpha_j_sortred=torch.index_select(alpha_j,0,index1)\n",
    "        judge=torch.zeros(size=alpha_j_abs.size())\n",
    "    \n",
    "        for l in range(K):\n",
    "            judge[l]=(torch.sum(alpha_j_abs[0:l+1])-lamd)/(l+1)\n",
    "    \n",
    "        max_index=torch.argmax(judge)\n",
    "    \n",
    "    \n",
    "        for k in range(max_index):\n",
    "            beta[j_round,k]=torch.sign(alpha_j_sortred[k])/(max_index+1)*(torch.sum(alpha_j_abs[0:max_index+1])-lamd)\n",
    "\n",
    "        for k in range(max_index,K):\n",
    "            beta[j_round,k]=alpha_j_sortred[k]\n",
    "\n",
    "        b,index2=torch.sort(index1)\n",
    "    \n",
    "        beta[j_round,:]=torch.index_select(beta[j_round,:],0,index2)\n",
    "   \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(1391.7717)\ntensor(78.2791)\ntensor(4.3912)\ntensor(0.3057)\ntensor(0.0297)\ntensor(0.0037)\ntensor(0.0005)\ntensor(8.0211e-05)\n%f tensor([[ 2.0005e+00,  3.9999e+00, -4.0004e+00, -5.0070e+00, -3.9987e+00],\n        [ 2.0008e+00,  8.1062e-05, -4.9993e+00, -4.9949e+00, -4.0024e+00],\n        [-4.1127e-05, -5.0000e+00, -2.0001e+00, -1.0045e+00,  4.0044e+00],\n        [-4.9996e+00,  2.0000e+00,  1.0000e+00, -1.9881e+00, -1.9967e+00],\n        [-4.9999e+00, -4.0000e+00, -1.3995e-04, -2.0035e+00, -2.8131e-03],\n        [-5.0003e+00, -5.0000e+00,  1.0002e+00, -3.9946e+00, -4.9993e+00],\n        [-1.0001e+00, -3.0000e+00, -5.0002e+00, -1.8835e-03,  4.0008e+00],\n        [ 2.0002e+00, -4.0000e+00,  1.0001e+00,  3.0033e+00,  9.9798e-01],\n        [-4.9999e+00,  4.0000e+00,  1.9998e+00,  2.0042e+00, -2.9993e+00],\n        [-3.9998e+00, -1.0000e+00,  1.9998e+00, -2.0017e+00, -3.0019e+00]])\n%f tensor([[ 2,  4, -4, -5, -4],\n        [ 2,  0, -5, -5, -4],\n        [ 0, -5, -2, -1,  4],\n        [-5,  2,  1, -2, -2],\n        [-5, -4,  0, -2,  0],\n        [-5, -5,  1, -4, -5],\n        [-1, -3, -5,  0,  4],\n        [ 2, -4,  1,  3,  1],\n        [-5,  4,  2,  2, -3],\n        [-4, -1,  2, -2, -3]])\n"
    }
   ],
   "source": [
    "delta_loss=100\n",
    "while(delta_loss>=0.001):\n",
    "    for j_round in range(p):\n",
    "        beta=single_blcok(beta,p,K,lamd,X,Y,C,D,j_round)\n",
    "    loss_new=Loss(Y,beta,X,lamd,p,K)\n",
    "    delta_loss=torch.abs(loss_new-loss)\n",
    "    loss=loss_new\n",
    "    print(Loss(Y,beta,X,lamd,p,K))\n",
    "\n",
    "print(\"%f\",beta)\n",
    "print(\"%f\",beta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# alpha=beta\n",
    "# for j in range(p):\n",
    "#     for k in range(K):\n",
    "#         alpha[j,k]=C[j,k]-torch.matmul(beta[:,k].flatten().float(),D[:,j,k].flatten().float())+beta[j,k]*D[j,j,k]\n",
    "# print (alpha)\n",
    "# print(Loss(Y,alpha,X,lamd,p,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for j in range(p):\n",
    "    \n",
    "#     if (torch.sum(torch.abs(alpha[j,:]))<=lamd):\n",
    "#         beta[j,:]=0\n",
    "    \n",
    "#     alpha_j=alpha[j,:]\n",
    "#     alpha_j_abs=torch.abs(alpha_j)\n",
    "#     alpha_sorted,index1=torch.sort(alpha_j_abs,descending=True)\n",
    "#     alpha_j_sortred=torch.index_select(alpha_j,0,index1)\n",
    "#     judge=torch.zeros(size=alpha_j_abs.size())\n",
    "    \n",
    "#     for l in range(K):\n",
    "#         judge[l]=(torch.sum(alpha_j_abs[0:l+1])-lamd)/(l+1)\n",
    "    \n",
    "#     max_index=torch.argmax(judge)\n",
    "    \n",
    "    \n",
    "#     for k in range(max_index):\n",
    "#         beta[j,k]=torch.sign(alpha_j_sortred[k])/(max_index+1)*(torch.sum(alpha_j_abs[0:max_index+1])-lamd)\n",
    "\n",
    "#     for k in range(max_index,K):\n",
    "#         beta[j,k]=alpha_j_sortred[k]\n",
    "\n",
    "#     b,index2=torch.sort(index1)\n",
    "    \n",
    "#     beta[j,:]=torch.index_select(beta[j,:],0,index2)\n",
    "    \n",
    "# print(beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(8.0211e-05)\n"
    }
   ],
   "source": [
    "loss=Loss(Y,beta,X,lamd,p,K)\n",
    "print(loss)\n"
   ]
  }
 ]
}