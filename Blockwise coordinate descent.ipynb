{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596029210931",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(Y,beta,X,lamd,p,K):\n",
    "    sum=0\n",
    "    \n",
    "    for k in range(K):\n",
    "        sum_betaX=0\n",
    "\n",
    "        for j in range(p):\n",
    "            sum_betaX=sum_betaX+beta[j,k]*X[j,k,:]\n",
    "\n",
    "        sum=sum+0.5*torch.norm(Y[k,:].flatten()-sum_betaX.flatten())**2\n",
    "    \n",
    "    norm_infinite,indice=torch.max(torch.abs(beta),1)\n",
    "    sum=sum+lamd*torch.sum(norm_infinite)\n",
    "\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initialize settings\n",
    "p=10\n",
    "K=5\n",
    "n_k=60\n",
    "lamd=1\n",
    "#guarantee each X's norm is 1\n",
    "X=torch.randn(p,K,n_k)\n",
    "for j in range(p):\n",
    "    for k in range(K):\n",
    "        X[j,k,:]=X[j,k,:]/torch.norm(X[j,k,:]) \n",
    "\n",
    "beta_true=torch.randint(low=-5,high=5,size=[p,K])   \n",
    "\n",
    "#calculate Y w.r.t noise\n",
    "Y=torch.zeros(K,n_k)\n",
    "for k in range(K):\n",
    "    sum=0\n",
    "    for j in range(p):\n",
    "        sum=sum+beta_true[j,k]*X[j,k,:]\n",
    "    Y[k,:]=sum+torch.tensor(np.random.normal(loc=0,scale=0,size=X[j,k,:].size())).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C_ij\n",
    "C=torch.zeros(p,K)\n",
    "for j in range(p):\n",
    "    for k in range(K):\n",
    "        C[j,k]=torch.matmul(X[j,k,:].flatten(),Y[k,:].flatten())\n",
    "       \n",
    "#D_ij^k\n",
    "D=torch.zeros(p,p,K)\n",
    "for k in range(K):\n",
    "    for i in range(p):\n",
    "        for j in range(p):\n",
    "            D[i,j,k]=torch.matmul(X[i,k,:].flatten(),X[j,k,:].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(12343.5205)\n"
    }
   ],
   "source": [
    "#initialize beta and calculate loss\n",
    "beta=torch.tensor(np.random.normal(loc=0,scale=25,size=beta_true.size())).float()\n",
    "loss=Loss(Y,beta,X,lamd,p,K)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operator for each block\n",
    "def single_blcok(beta,p,K,lamd,X,Y,C,D,j_round):\n",
    "    \n",
    "    alpha=beta\n",
    "    for k in range(K):\n",
    "        beta[j_round,k]=C[j_round,k]-torch.matmul(beta[:,k].flatten().float(),D[:,j_round,k].flatten().float())+beta[j_round,k]*D[j_round,j_round,k]\n",
    "\n",
    "    if (lamd!=0):\n",
    "        if (torch.sum(torch.abs(alpha[j_round,:]))<=lamd):\n",
    "            beta[j_round,:]=0\n",
    "    \n",
    "        alpha_j=alpha[j_round,:]\n",
    "        alpha_j_abs=torch.abs(alpha_j)\n",
    "        alpha_sorted,index1=torch.sort(alpha_j_abs,descending=True)\n",
    "        alpha_j_sortred=torch.index_select(alpha_j,0,index1)\n",
    "        judge=torch.zeros(size=alpha_j_abs.size())\n",
    "    \n",
    "        for l in range(K):\n",
    "            judge[l]=(torch.sum(alpha_j_abs[0:l+1])-lamd)/(l+1)\n",
    "    \n",
    "        max_index=torch.argmax(judge)\n",
    "    \n",
    "    \n",
    "        for k in range(max_index):\n",
    "            beta[j_round,k]=torch.sign(alpha_j_sortred[k])/(max_index+1)*(torch.sum(alpha_j_abs[0:max_index+1])-lamd)\n",
    "\n",
    "        for k in range(max_index,K):\n",
    "            beta[j_round,k]=alpha_j_sortred[k]\n",
    "\n",
    "        b,index2=torch.sort(index1)\n",
    "    \n",
    "        beta[j_round,:]=torch.index_select(beta[j_round,:],0,index2)\n",
    "   \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(705.4390)\ntensor(91.7125)\ntensor(58.2465)\ntensor(51.8501)\ntensor(51.6495)\ntensor(51.5752)\n%f tensor([[-4.5763, -4.6161, -4.5763,  4.3063, -1.1352],\n        [-1.9622,  1.9622, -0.2651, -1.9622, -1.9622],\n        [-3.4638,  1.9726, -3.4638,  3.4638,  1.1844],\n        [ 0.5130, -0.0171,  0.5130, -0.5130,  0.5130],\n        [ 2.9913,  2.9913, -1.9746,  2.9913,  2.9913],\n        [ 1.7899,  1.8830, -2.2600,  0.4512, -2.2600],\n        [-3.3614, -3.5382,  1.6277,  3.5621,  3.9829],\n        [-2.5973, -3.2044, -3.2044, -1.6488, -3.3816],\n        [-2.3800, -1.2262, -2.3800,  2.3800, -2.3800],\n        [-4.0316,  4.2347,  0.7068, -0.8008, -1.6491]])\n%f tensor([[-5, -5, -5,  4, -1],\n        [ 0,  1,  0, -5, -4],\n        [-4,  2, -4,  4,  1],\n        [ 0,  0,  0, -3,  0],\n        [ 2,  3, -2,  4,  4],\n        [ 2,  2, -4,  1, -3],\n        [-3, -5,  2,  4,  4],\n        [-2, -4, -4, -2, -3],\n        [-1, -1, -3,  2, -5],\n        [-5,  4,  1, -1, -2]])\n"
    }
   ],
   "source": [
    "delta_loss=100\n",
    "while(delta_loss>=0.1):\n",
    "    for j_round in range(p):\n",
    "        beta=single_blcok(beta,p,K,lamd,X,Y,C,D,j_round)\n",
    "    loss_new=Loss(Y,beta,X,lamd,p,K)\n",
    "    delta_loss=torch.abs(loss_new-loss)\n",
    "    loss=loss_new\n",
    "    print(Loss(Y,beta,X,lamd,p,K))\n",
    "\n",
    "print(\"%f\",beta)\n",
    "print(\"%f\",beta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(51.5752)\n"
    }
   ],
   "source": [
    "loss=Loss(Y,beta,X,lamd,p,K)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(34.7340)\ntensor(34.7991)\ntensor(34.5307)\ntensor(34.6821)\ntensor(34.7308)\ntensor(34.7420)\ntensor(34.7440)\n"
    }
   ],
   "source": [
    "lamd=lamd*0.5\n",
    "delta_loss=100\n",
    "while(delta_loss>=0.01):\n",
    "    for j_round in range(p):\n",
    "        beta=single_blcok(beta,p,K,lamd,X,Y,C,D,j_round)\n",
    "    loss_new=Loss(Y,beta,X,lamd,p,K)\n",
    "    delta_loss=torch.abs(loss_new-loss)\n",
    "    loss=loss_new\n",
    "    print(Loss(Y,beta,X,lamd,p,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(26.1333)\ntensor(26.1740)\ntensor(26.1793)\ntensor(26.1801)\n"
    }
   ],
   "source": [
    "lamd=lamd*0.5\n",
    "delta_loss=100\n",
    "while(delta_loss>=0.001):\n",
    "    for j_round in range(p):\n",
    "        beta=single_blcok(beta,p,K,lamd,X,Y,C,D,j_round)\n",
    "    loss_new=Loss(Y,beta,X,lamd,p,K)\n",
    "    delta_loss=torch.abs(loss_new-loss)\n",
    "    loss=loss_new\n",
    "    print(Loss(Y,beta,X,lamd,p,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(21.7436)\ntensor(21.7465)\n"
    }
   ],
   "source": [
    "lamd=lamd*0.5\n",
    "delta_loss=100\n",
    "while(delta_loss>=0.1):\n",
    "    for j_round in range(p):\n",
    "        beta=single_blcok(beta,p,K,lamd,X,Y,C,D,j_round)\n",
    "    loss_new=Loss(Y,beta,X,lamd,p,K)\n",
    "    delta_loss=torch.abs(loss_new-loss)\n",
    "    loss=loss_new\n",
    "    print(Loss(Y,beta,X,lamd,p,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "%f tensor([[-5.2815, -4.6047, -5.0564,  4.2948, -1.1585],\n        [ 0.0139,  2.1390, -2.1390, -2.1390, -2.1390],\n        [-3.6839,  1.9724, -3.6839,  3.6839,  1.1959],\n        [-0.1457, -0.0223,  0.8376, -0.8376,  0.8376],\n        [ 3.1888,  3.1888, -2.2216,  3.1888,  3.1888],\n        [ 1.7509,  1.8871, -2.4215,  0.5126, -2.4215],\n        [-2.6366, -3.5898,  1.1301,  3.6006,  3.9763],\n        [-2.3380, -3.3363, -3.3363, -1.6959, -3.3321],\n        [-2.5775, -1.2053, -2.5775,  2.5775, -2.5775],\n        [-4.9547,  4.2066,  0.1398, -0.7992, -1.6710]])\n%f tensor([[-5, -5, -5,  4, -1],\n        [ 0,  1,  0, -5, -4],\n        [-4,  2, -4,  4,  1],\n        [ 0,  0,  0, -3,  0],\n        [ 2,  3, -2,  4,  4],\n        [ 2,  2, -4,  1, -3],\n        [-3, -5,  2,  4,  4],\n        [-2, -4, -4, -2, -3],\n        [-1, -1, -3,  2, -5],\n        [-5,  4,  1, -1, -2]])\n"
    }
   ],
   "source": [
    "print(\"%f\",beta)\n",
    "print(\"%f\",beta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}