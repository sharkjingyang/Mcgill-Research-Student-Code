{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596003010537",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(Y,beta,X,lamd,p,K):\n",
    "    sum=0\n",
    "    \n",
    "    for k in range(K):\n",
    "        sum_betaX=0\n",
    "\n",
    "        for j in range(p):\n",
    "            sum_betaX=sum_betaX+beta[j,k]*X[j,k,:]\n",
    "\n",
    "        sum=sum+0.5*torch.norm(Y[k,:].flatten()-sum_betaX.flatten())**2\n",
    "    \n",
    "    norm_infinite,indice=torch.max(torch.abs(beta),1)\n",
    "    sum=sum+lamd*torch.sum(norm_infinite)\n",
    "\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initialize settings\n",
    "p=10\n",
    "K=5\n",
    "n_k=60\n",
    "lamd=1\n",
    "\n",
    "X=torch.randn(p,K,n_k)\n",
    "for j in range(p):\n",
    "    for k in range(K):\n",
    "        X[j,k,:]=X[j,k,:]/torch.norm(X[j,k,:])\n",
    "\n",
    "beta_true=torch.randint(low=-5,high=5,size=[p,K])\n",
    "# print(beta_true)\n",
    "Y=torch.zeros(K,n_k)\n",
    "\n",
    "for k in range(K):\n",
    "    sum=0\n",
    "    for j in range(p):\n",
    "        sum=sum+beta_true[j,k]*X[j,k,:]\n",
    "    Y[k,:]=sum+torch.tensor(np.random.normal(loc=0,scale=0,size=X[j,k,:].size())).float()\n",
    "\n",
    "# print(Y.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C_ij\n",
    "C=torch.zeros(p,K)\n",
    "for j in range(p):\n",
    "    for k in range(K):\n",
    "        C[j,k]=torch.matmul(X[j,k,:].flatten(),Y[k,:].flatten())\n",
    "        # print(C[j,k])\n",
    "#D_ij^k\n",
    "D=torch.zeros(p,p,K)\n",
    "for k in range(K):\n",
    "    for i in range(p):\n",
    "        for j in range(p):\n",
    "            D[i,j,k]=torch.matmul(X[i,k,:].flatten(),X[j,k,:].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(13209.6250)\n"
    }
   ],
   "source": [
    "# beta=beta_true+torch.tensor(np.random.normal(loc=0,scale=9,size=beta_true.size())).float()\n",
    "beta=torch.tensor(np.random.normal(loc=0,scale=25,size=beta_true.size())).float()\n",
    "loss=Loss(Y,beta,X,lamd,p,K)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_blcok(beta,p,K,lamd,X,Y,C,D,j_round):\n",
    "    \n",
    "    alpha=beta\n",
    "    for k in range(K):\n",
    "        beta[j_round,k]=C[j_round,k]-torch.matmul(beta[:,k].flatten().float(),D[:,j_round,k].flatten().float())+beta[j_round,k]*D[j_round,j_round,k]\n",
    "\n",
    "    if (lamd!=0):\n",
    "        if (torch.sum(torch.abs(alpha[j_round,:]))<=lamd):\n",
    "            beta[j_round,:]=0\n",
    "    \n",
    "        alpha_j=alpha[j_round,:]\n",
    "        alpha_j_abs=torch.abs(alpha_j)\n",
    "        alpha_sorted,index1=torch.sort(alpha_j_abs,descending=True)\n",
    "        alpha_j_sortred=torch.index_select(alpha_j,0,index1)\n",
    "        judge=torch.zeros(size=alpha_j_abs.size())\n",
    "    \n",
    "        for l in range(K):\n",
    "            judge[l]=(torch.sum(alpha_j_abs[0:l+1])-lamd)/(l+1)\n",
    "    \n",
    "        max_index=torch.argmax(judge)\n",
    "    \n",
    "    \n",
    "        for k in range(max_index):\n",
    "            beta[j_round,k]=torch.sign(alpha_j_sortred[k])/(max_index+1)*(torch.sum(alpha_j_abs[0:max_index+1])-lamd)\n",
    "\n",
    "        for k in range(max_index,K):\n",
    "            beta[j_round,k]=alpha_j_sortred[k]\n",
    "\n",
    "        b,index2=torch.sort(index1)\n",
    "    \n",
    "        beta[j_round,:]=torch.index_select(beta[j_round,:],0,index2)\n",
    "   \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(769.2280)\ntensor(136.0310)\ntensor(67.8733)\ntensor(53.7712)\ntensor(48.3850)\ntensor(47.6117)\ntensor(46.5234)\ntensor(46.6319)\ntensor(46.6176)\ntensor(46.6183)\n%f tensor([[-4.0864,  4.3017,  3.2575,  3.7427, -0.0534],\n        [-3.0852, -2.8753, -2.8753,  0.2821, -0.1163],\n        [ 2.8477, -2.8477, -1.7008, -2.8477, -1.5585],\n        [ 0.8479, -2.4942, -2.4942,  1.3078,  1.0989],\n        [-5.1669,  2.0814, -1.2683,  3.9273, -3.0540],\n        [-3.7731, -4.0670, -3.7191, -4.0670,  4.0670],\n        [ 3.3890,  3.3890, -3.4010, -2.7718, -2.9910],\n        [-4.9553,  2.8746, -2.9675,  0.3410, -0.9453],\n        [ 2.5224,  2.9679, -1.5507,  1.6639, -2.6724],\n        [-2.1463,  0.3278,  2.1463, -2.1463,  2.1463]])\n%f tensor([[-5,  4,  3,  4,  0],\n        [-3, -3, -3,  0,  0],\n        [ 2, -4, -2, -5, -2],\n        [ 1, -3, -5,  2,  1],\n        [-5,  2, -1,  4, -3],\n        [-4, -5, -3, -5,  4],\n        [ 4,  4, -3, -3, -3],\n        [-5,  3, -2,  0, -1],\n        [ 3,  3, -2,  2, -3],\n        [-1,  0,  4, -3,  4]])\n"
    }
   ],
   "source": [
    "delta_loss=100\n",
    "while(delta_loss>=0.01):\n",
    "    for j_round in range(p):\n",
    "        beta=single_blcok(beta,p,K,lamd,X,Y,C,D,j_round)\n",
    "    loss_new=Loss(Y,beta,X,lamd,p,K)\n",
    "    delta_loss=torch.abs(loss_new-loss)\n",
    "    loss=loss_new\n",
    "    print(Loss(Y,beta,X,lamd,p,K))\n",
    "\n",
    "print(\"%f\",beta)\n",
    "print(\"%f\",beta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(46.6183)\n"
    }
   ],
   "source": [
    "loss=Loss(Y,beta,X,lamd,p,K)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(28.1221)\ntensor(28.0865)\ntensor(28.1024)\ntensor(28.1363)\ntensor(28.1072)\ntensor(28.1039)\n"
    }
   ],
   "source": [
    "lamd=lamd*0.5\n",
    "delta_loss=100\n",
    "while(delta_loss>=0.01):\n",
    "    for j_round in range(p):\n",
    "        beta=single_blcok(beta,p,K,lamd,X,Y,C,D,j_round)\n",
    "    loss_new=Loss(Y,beta,X,lamd,p,K)\n",
    "    delta_loss=torch.abs(loss_new-loss)\n",
    "    loss=loss_new\n",
    "    print(Loss(Y,beta,X,lamd,p,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(18.4646)\ntensor(18.4282)\ntensor(18.4236)\ntensor(18.4236)\n"
    }
   ],
   "source": [
    "lamd=lamd*0.5\n",
    "delta_loss=100\n",
    "while(delta_loss>=0.001):\n",
    "    for j_round in range(p):\n",
    "        beta=single_blcok(beta,p,K,lamd,X,Y,C,D,j_round)\n",
    "    loss_new=Loss(Y,beta,X,lamd,p,K)\n",
    "    delta_loss=torch.abs(loss_new-loss)\n",
    "    loss=loss_new\n",
    "    print(Loss(Y,beta,X,lamd,p,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(13.5794)\ntensor(13.5629)\ntensor(13.5608)\ntensor(13.5607)\n"
    }
   ],
   "source": [
    "lamd=lamd*0.5\n",
    "delta_loss=100\n",
    "while(delta_loss>=0.001):\n",
    "    for j_round in range(p):\n",
    "        beta=single_blcok(beta,p,K,lamd,X,Y,C,D,j_round)\n",
    "    loss_new=Loss(Y,beta,X,lamd,p,K)\n",
    "    delta_loss=torch.abs(loss_new-loss)\n",
    "    loss=loss_new\n",
    "    print(Loss(Y,beta,X,lamd,p,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "%f tensor([[-4.8853,  4.2277,  3.2335,  3.7580, -0.0680],\n        [-2.7347, -3.0122, -3.0122,  0.2501, -0.1452],\n        [ 3.0834, -3.0834, -1.7113, -3.0834, -1.6001],\n        [ 0.6321, -2.7181, -2.7181,  1.4280,  1.0756],\n        [-5.2410,  1.9944, -1.2227,  3.9404, -3.0203],\n        [-3.9901, -4.3473, -3.6446, -4.3473,  4.3473],\n        [ 3.7869,  3.7377, -3.3761, -2.8060, -3.0325],\n        [-5.0319,  2.8636, -2.8824,  0.3204, -0.9733],\n        [ 2.8140,  2.8152, -1.5972,  1.7129, -2.6474],\n        [-2.2606,  0.1865,  2.2606, -2.2606,  2.2606]])\n%f tensor([[-5,  4,  3,  4,  0],\n        [-3, -3, -3,  0,  0],\n        [ 2, -4, -2, -5, -2],\n        [ 1, -3, -5,  2,  1],\n        [-5,  2, -1,  4, -3],\n        [-4, -5, -3, -5,  4],\n        [ 4,  4, -3, -3, -3],\n        [-5,  3, -2,  0, -1],\n        [ 3,  3, -2,  2, -3],\n        [-1,  0,  4, -3,  4]])\n"
    }
   ],
   "source": [
    "print(\"%f\",beta)\n",
    "print(\"%f\",beta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}